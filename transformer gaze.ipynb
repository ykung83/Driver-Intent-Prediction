{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabb209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Input, Dense\n",
    "from tensorflow.keras.layers import LayerNormalization, Layer\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import convert_to_tensor, string, float32, shape, reshape\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154f3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "trainset = np.load('C:/Users/ykung/Downloads/facecamera/trainset.npy')\n",
    "trainsety = np.load('C:/Users/ykung/Downloads/facecamera/trainsety.npy')\n",
    "testset = np.load('C:/Users/ykung/Downloads/facecamera/testset.npy')\n",
    "testsety = np.load('C:/Users/ykung/Downloads/facecamera/testsety.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e8bba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = np.reshape(trainset, (68736,90,2))\n",
    "trainsety = np.reshape(trainsety, (68736,1,1))\n",
    "testset = np.reshape(testset, (18816,90,2))\n",
    "testsety = np.reshape(testsety, (18816,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed4b876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrainsety = np.zeros((68736,5))\n",
    "for i in range(68736):\n",
    "    val1 = int(trainsety[i,0,0])\n",
    "    newtrainsety[i,val1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469e6c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "newtestsety = np.zeros((18816,5))\n",
    "for i in range(18816):\n",
    "    val1 = int(testsety[i,0,0])\n",
    "    newtestsety[i,val1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a3b77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "newtrainset = np.zeros((68736,90,2))\n",
    "for i in range(68736):\n",
    "    for j in range(90):\n",
    "        val1 = trainset[i,j,0]\n",
    "        val2 = trainset[i,j,1]\n",
    "        if val1 < -1500:\n",
    "            val1 = -1500\n",
    "        if val1 > 1499:\n",
    "            val1 = 1499\n",
    "        if val2 < -1500:\n",
    "            val2 = -1500\n",
    "        if val2 > 1499:\n",
    "            val2 = 1499\n",
    "        newtrainset[i,j,0]=int(val1+1500)\n",
    "        newtrainset[i,j,1]=int(val2+1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f8d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "newtestset = np.zeros((18816,90,2))\n",
    "for i in range(18816):\n",
    "    for j in range(90):\n",
    "        val1 = testset[i,j,0]\n",
    "        val2 = testset[i,j,1]\n",
    "        if val1 < -1500:\n",
    "            val1 = -1500\n",
    "        if val1 > 1499:\n",
    "            val1 = 1499\n",
    "        if val2 < -1500:\n",
    "            val2 = -1500\n",
    "        if val2 > 1499:\n",
    "            val2 = 1499\n",
    "        newtestset[i,j,0]=int(val1+1500)\n",
    "        newtestset[i,j,1]=int(val2+1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "976182d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtrainset.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07112163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2296.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtestset.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a67d7c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12137afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding for gaze and time step\n",
    "class EmbeddingLayer(Layer):\n",
    "    def __init__(self, sequence_length, input_size, embed_dim):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.word_embedding = Embedding(input_dim=input_size, output_dim=embed_dim)\n",
    "        self.position_embedding = Embedding(input_dim=sequence_length, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, tokens):\n",
    "        sequence_length = shape(tokens)[-1]\n",
    "        all_positions = range(start=0, limit=sequence_length, delta=1)\n",
    "        positions_encoding = self.position_embedding(all_positions)\n",
    "        words_encoding = self.word_embedding(tokens)\n",
    "        return positions_encoding + words_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d720b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder layer\n",
    "class EncoderLayer(Layer):\n",
    "    def __init__(self, total_heads, total_dense_units, embed_dim):\n",
    "        super(EncoderLayer, self).__init__()# Multihead attention layer\n",
    "        self.multihead = MultiHeadAttention(num_heads=total_heads, key_dim=embed_dim)# Feed forward network layer\n",
    "        self.nnw = Sequential([Dense(total_dense_units, activation=\"relu\"),\n",
    "        Dense(embed_dim)])# Normalization\n",
    "        self.normalize_layer = LayerNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn_output = self.multihead(inputs, inputs)\n",
    "        normalize_attn = self.normalize_layer(inputs + attn_output)\n",
    "        nnw_output = self.nnw(normalize_attn)\n",
    "        final_output = self.normalize_layer(normalize_attn + nnw_output)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31d7979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 90, 2)]           0         \n",
      "                                                                 \n",
      " embedding_layer_1 (Embeddi  (None, 90, 2, 10)         30900     \n",
      " ngLayer)                                                        \n",
      "                                                                 \n",
      " encoder_layer_1 (EncoderLa  (None, 90, 2, 10)         1740      \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 90, 2, 40)         440       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 7200)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 36005     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69085 (269.86 KB)\n",
      "Trainable params: 69085 (269.86 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# transformer\n",
    "embed_dim = 10\n",
    "num_heads = 2\n",
    "total_dense_units = 40\n",
    "sequence_length = 90\n",
    "input_size = 3000\n",
    "n_classes = 5\n",
    "\n",
    "# Our two custom layers\n",
    "embedding_layer = EmbeddingLayer(sequence_length, input_size, embed_dim)\n",
    "encoder_layer = EncoderLayer(num_heads, total_dense_units, embed_dim)\n",
    "\n",
    "# Start connecting the layers together\n",
    "inputs = Input(shape=(sequence_length,2,))\n",
    "emb = embedding_layer(inputs)\n",
    "enc = encoder_layer(emb)\n",
    "d = Dense(total_dense_units, activation=\"relu\")(enc)\n",
    "flat = Flatten()(d)\n",
    "outputs = Dense(n_classes, activation=\"softmax\")(flat)\n",
    "\n",
    "# Construct the transformer model\n",
    "transformer_model = Model(inputs=inputs, outputs=outputs)\n",
    "transformer_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy', 'Precision', 'Recall'])\n",
    "transformer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9ea5928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1375/1375 [==============================] - 53s 38ms/step - loss: 0.3152 - accuracy: 0.8835 - precision: 0.8986 - recall: 0.8682 - val_loss: 0.3747 - val_accuracy: 0.8525 - val_precision: 0.8545 - val_recall: 0.8501\n",
      "Epoch 2/4\n",
      "1375/1375 [==============================] - 52s 38ms/step - loss: 0.2019 - accuracy: 0.9272 - precision: 0.9295 - recall: 0.9246 - val_loss: 0.3851 - val_accuracy: 0.8610 - val_precision: 0.8620 - val_recall: 0.8601\n",
      "Epoch 3/4\n",
      "1375/1375 [==============================] - 52s 38ms/step - loss: 0.1701 - accuracy: 0.9387 - precision: 0.9408 - recall: 0.9367 - val_loss: 0.3795 - val_accuracy: 0.8680 - val_precision: 0.8712 - val_recall: 0.8651\n",
      "Epoch 4/4\n",
      "1375/1375 [==============================] - 52s 38ms/step - loss: 0.1426 - accuracy: 0.9493 - precision: 0.9513 - recall: 0.9474 - val_loss: 0.5075 - val_accuracy: 0.8410 - val_precision: 0.8439 - val_recall: 0.8389\n"
     ]
    }
   ],
   "source": [
    "history = transformer_model.fit(newtrainset, newtrainsety, epochs = 4, batch_size = 50, verbose = 1, validation_data = (newtestset, newtestsety))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e05a589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtrainset[39,5,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acde37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
